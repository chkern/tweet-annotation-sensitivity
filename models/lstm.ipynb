{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHZ2IZ_wE89h"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VN4ZusJOE89i"
      },
      "outputs": [],
      "source": [
        "label_to_class = \"hate.speech\" # enter the label to be classified\n",
        "version = \"A\" # enter the version\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wiId22Up3VYb"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import numpy as np\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "import nltk\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Q_JA4Z0J3VYb"
      },
      "outputs": [],
      "source": [
        "# build the model\n",
        "class LSTM(nn.Module):\n",
        "  def __init__(self,vocab_size, emb_size, lstm_size, hidden_size, dropout):\n",
        "    super().__init__()\n",
        "    self.emb = nn.Embedding(vocab_size, emb_size)\n",
        "    self.lstm = nn.LSTM(emb_size, lstm_size, bidirectional=True, batch_first=True)\n",
        "    self.hidden = nn.Linear(lstm_size*2, hidden_size)\n",
        "    self.linear = nn.Linear(hidden_size, 1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, input, lengths): # input.shape: (batch_size, texts_length)\n",
        "    emb = self.emb(input) # (batch_size, texts_length, emb_size)\n",
        "    emb = self.dropout(emb)\n",
        "    packed = pack_padded_sequence(emb, lengths, batch_first=True, enforce_sorted=False)  #PackedSequence: data (packed length, lstm_size*2)\n",
        "    lstm, _ = self.lstm(packed.float())  # (batch_size, texts_length, lstm_size*2)\n",
        "    padded, _ = pad_packed_sequence(lstm, batch_first=True)\n",
        "    output = torch.max(padded, dim=1).values # max pooling, (batch_size, lstm_size*2)\n",
        "    output = self.hidden(self.dropout(output)) # (batch_size, hidden_size)\n",
        "    output = self.linear(self.dropout(output)) # (batch_size, 1)\n",
        "    output = self.sigmoid(output)\n",
        "    return output.squeeze() # (batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "T4Io0UcH3VYe"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 20\n",
        "BATCH_SIZE = 64\n",
        "EMB_SIZE = 512\n",
        "LSTM_SIZE = 512\n",
        "HIDDEN_SIZE = 256\n",
        "DROPOUT = 0.3\n",
        "VOCAB_SIZE=5000\n",
        "LEARNING_RATE = 5e-05\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = nltk.tokenize.TweetTokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# no drops\n",
        "# csv = pd.read_csv('../data/version'+version+'_train.csv',header=0)\n",
        "\n",
        "# # create a new csv df\n",
        "# csv_new = pd.DataFrame(csv, columns=[label_to_class, \"tweet_hashed\"])\n",
        "# # drop all rows that have any NaN values\n",
        "# csv_new_clean = csv_new.dropna(axis=0,how=\"any\")\n",
        "\n",
        "# drops to 3 examples per tweet\n",
        "csv = pd.read_csv('../data/version'+version+'_train.csv',header=0)\n",
        "# create a new csv df\n",
        "csv_new = pd.DataFrame(csv, columns=[label_to_class, \"tweet_hashed\"])\n",
        "# drop all rows that have any NaN values\n",
        "csv_new_clean = csv_new.dropna(axis=0,how=\"any\")\n",
        "# save tweets into a list\n",
        "tweet=list(csv_new_clean['tweet_hashed'])\n",
        "# count tweet freqs\n",
        "tweet_count=Counter(tweet)\n",
        "for t, c in tweet_count.items():\n",
        "    if c > 3:\n",
        "        # get the index for a specific tweet into a list\n",
        "        index = csv_new_clean[csv_new_clean.tweet_hashed == t].index.tolist()\n",
        "        # randomly choose index to drop\n",
        "        index_to_drop = random.sample(index, c-3)\n",
        "        csv_new_clean = csv_new_clean.drop(index_to_drop, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLD_0oAU9_6B"
      },
      "outputs": [],
      "source": [
        "train_csv, dev_csv = train_test_split(csv_new_clean, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMb3fzud6k4G"
      },
      "outputs": [],
      "source": [
        "X_train = [tokenizer.tokenize(text.lower()) for text in list(train_csv[\"tweet_hashed\"])]\n",
        "X_dev = [tokenizer.tokenize(text.lower()) for text in list(dev_csv[\"tweet_hashed\"])]\n",
        "\n",
        "y_train = list(train_csv[label_to_class])\n",
        "y_dev = list(dev_csv[label_to_class])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQ2iOqJZ6k4H"
      },
      "outputs": [],
      "source": [
        "train_data = list(zip(X_train, y_train))\n",
        "dev_data = list(zip(X_dev, y_dev))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hchtnPii6k4H"
      },
      "outputs": [],
      "source": [
        "vocab = build_vocab_from_iterator(X_train, max_tokens=VOCAB_SIZE, specials=[\"<unk>\", \"<pad>\"])\n",
        "vocab.set_default_index(vocab[\"<unk>\"])  # index 0 reserved for '<unk>' as default, 1 reserved for '<pad>'\n",
        "torch.save(vocab, \"LSTM.vocab.\"+label_to_class+version)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RW_F8wlH9afa"
      },
      "outputs": [],
      "source": [
        "def collate(batch, vocab, device):\n",
        "    texts, labels = zip(*batch)\n",
        "    lengths = [len(text) for text in texts]\n",
        "    word_ids = [[vocab[word] for word in text] for text in texts]\n",
        "    texts = pad_sequence([torch.LongTensor(ids) for ids in word_ids], batch_first=True, padding_value=1)\n",
        "    return texts.to(device), torch.tensor(labels).to(device), torch.LongTensor(lengths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCbeba2FV5Rh"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(dataset=train_data,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          shuffle=True,\n",
        "                          collate_fn=lambda batch: collate(batch, vocab, DEVICE))\n",
        "dev_loader = DataLoader(dataset=dev_data,\n",
        "                        batch_size=BATCH_SIZE,\n",
        "                        collate_fn=lambda batch: collate(batch, vocab, DEVICE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EKPiWpZ3VYf"
      },
      "outputs": [],
      "source": [
        "model = LSTM(VOCAB_SIZE, EMB_SIZE, LSTM_SIZE, HIDDEN_SIZE, DROPOUT).to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "criterion = nn.BCELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-g2v8Gc3VYf",
        "outputId": "a70abf9a-e284-473b-bcd9-3ff1863df5b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start training...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 118/118 [00:03<00:00, 37.81it/s]\n",
            "100%|██████████| 30/30 [00:00<00:00, 138.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: train loss: 0.6235, train acc: 0.6780\n",
            "Epoch 1: dev loss: 0.6184, dev acc: 0.6775\n",
            "*** Epoch 1: dev acc higher than best dev acc, model saved!\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 118/118 [00:03<00:00, 36.06it/s]\n",
            "100%|██████████| 30/30 [00:00<00:00, 109.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2: train loss: 0.6068, train acc: 0.6859\n",
            "Epoch 2: dev loss: 0.6081, dev acc: 0.6858\n",
            "*** Epoch 2: dev acc higher than best dev acc, model saved!\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 118/118 [00:03<00:00, 38.57it/s]\n",
            "100%|██████████| 30/30 [00:00<00:00, 145.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3: train loss: 0.5888, train acc: 0.6965\n",
            "Epoch 3: dev loss: 0.5796, dev acc: 0.7004\n",
            "*** Epoch 3: dev acc higher than best dev acc, model saved!\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 118/118 [00:03<00:00, 38.95it/s]\n",
            "100%|██████████| 30/30 [00:00<00:00, 141.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4: train loss: 0.5702, train acc: 0.7142\n",
            "Epoch 4: dev loss: 0.5543, dev acc: 0.7390\n",
            "*** Epoch 4: dev acc higher than best dev acc, model saved!\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 118/118 [00:03<00:00, 38.81it/s]\n",
            "100%|██████████| 30/30 [00:00<00:00, 131.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss: 0.5405, train acc: 0.7349\n",
            "Epoch 5: dev loss: 0.5309, dev acc: 0.7437\n",
            "*** Epoch 5: dev acc higher than best dev acc, model saved!\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 118/118 [00:03<00:00, 35.93it/s]\n",
            "100%|██████████| 30/30 [00:00<00:00, 109.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6: train loss: 0.5154, train acc: 0.7515\n",
            "Epoch 6: dev loss: 0.5091, dev acc: 0.7656\n",
            "*** Epoch 6: dev acc higher than best dev acc, model saved!\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 118/118 [00:03<00:00, 38.75it/s]\n",
            "100%|██████████| 30/30 [00:00<00:00, 135.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7: train loss: 0.4957, train acc: 0.7695\n",
            "Epoch 7: dev loss: 0.4983, dev acc: 0.7676\n",
            "*** Epoch 7: dev acc higher than best dev acc, model saved!\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 118/118 [00:03<00:00, 38.52it/s]\n",
            "100%|██████████| 30/30 [00:00<00:00, 134.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8: train loss: 0.4689, train acc: 0.7884\n",
            "Epoch 8: dev loss: 0.5206, dev acc: 0.7576\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 118/118 [00:03<00:00, 38.59it/s]\n",
            "100%|██████████| 30/30 [00:00<00:00, 135.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9: train loss: 0.4556, train acc: 0.7863\n",
            "Epoch 9: dev loss: 0.5114, dev acc: 0.7587\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 118/118 [00:03<00:00, 35.21it/s]\n",
            "100%|██████████| 30/30 [00:00<00:00, 117.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10: train loss: 0.4461, train acc: 0.7925\n",
            "Epoch 10: dev loss: 0.5089, dev acc: 0.7691\n",
            "*** Epoch 10: dev acc higher than best dev acc, model saved!\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 118/118 [00:03<00:00, 38.82it/s]\n",
            "100%|██████████| 30/30 [00:00<00:00, 130.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11: train loss: 0.4352, train acc: 0.7999\n",
            "Epoch 11: dev loss: 0.5229, dev acc: 0.7623\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 118/118 [00:03<00:00, 38.34it/s]\n",
            "100%|██████████| 30/30 [00:00<00:00, 138.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12: train loss: 0.4235, train acc: 0.8053\n",
            "Epoch 12: dev loss: 0.5312, dev acc: 0.7618\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 118/118 [00:03<00:00, 38.90it/s]\n",
            "100%|██████████| 30/30 [00:00<00:00, 145.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13: train loss: 0.4144, train acc: 0.8104\n",
            "Epoch 13: dev loss: 0.5377, dev acc: 0.7623\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 118/118 [00:03<00:00, 36.12it/s]\n",
            "100%|██████████| 30/30 [00:00<00:00, 115.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14: train loss: 0.4098, train acc: 0.8146\n",
            "Epoch 14: dev loss: 0.5465, dev acc: 0.7587\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 118/118 [00:03<00:00, 38.65it/s]\n",
            "100%|██████████| 30/30 [00:00<00:00, 141.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15: train loss: 0.4007, train acc: 0.8148\n",
            "Epoch 15: dev loss: 0.5814, dev acc: 0.7514\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 118/118 [00:03<00:00, 38.85it/s]\n",
            "100%|██████████| 30/30 [00:00<00:00, 142.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16: train loss: 0.3979, train acc: 0.8144\n",
            "Epoch 16: dev loss: 0.5512, dev acc: 0.7623\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 118/118 [00:03<00:00, 39.01it/s]\n",
            "100%|██████████| 30/30 [00:00<00:00, 142.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17: train loss: 0.3964, train acc: 0.8128\n",
            "Epoch 17: dev loss: 0.5691, dev acc: 0.7603\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 118/118 [00:03<00:00, 36.61it/s]\n",
            "100%|██████████| 30/30 [00:00<00:00, 117.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18: train loss: 0.3943, train acc: 0.8155\n",
            "Epoch 18: dev loss: 0.5711, dev acc: 0.7624\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 118/118 [00:03<00:00, 38.42it/s]\n",
            "100%|██████████| 30/30 [00:00<00:00, 146.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19: train loss: 0.3822, train acc: 0.8179\n",
            "Epoch 19: dev loss: 0.5740, dev acc: 0.7566\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 118/118 [00:03<00:00, 39.00it/s]\n",
            "100%|██████████| 30/30 [00:00<00:00, 141.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20: train loss: 0.3781, train acc: 0.8186\n",
            "Epoch 20: dev loss: 0.5935, dev acc: 0.7519\n",
            "\n",
            "Training finished! Best epoch is 10, best dev acc is 0.7691, 67.89233040809631 seconds used.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "best_dev_acc = 0\n",
        "best_epoch = 0\n",
        "print(f'Start training...')\n",
        "start_time = time.time()\n",
        "for epoch in range(EPOCHS):\n",
        "    # train\n",
        "    train_loss = 0\n",
        "    train_acc = 0\n",
        "    model.train()\n",
        "    for texts, labels, lengths in tqdm(train_loader):\n",
        "        output = model(texts, lengths)\n",
        "        preds = torch.round(output)\n",
        "        #acc = (output.ge(0.5) == labels).sum().item() / labels.size(0)\n",
        "        acc = torch.eq(labels, preds).sum().item() / labels.size(0)\n",
        "        model.zero_grad()\n",
        "        loss = criterion(output, labels.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "        train_acc += acc\n",
        "    train_loss, train_acc = train_loss / len(train_loader), train_acc / len(train_loader)\n",
        "    \n",
        "    # dev\n",
        "    dev_loss = 0\n",
        "    dev_acc = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for texts, labels, lengths in tqdm(dev_loader):\n",
        "            output = model(texts, lengths)\n",
        "            loss = criterion(output, labels.float())\n",
        "            preds = torch.round(output)\n",
        "            #acc = (output.ge(0.5) == labels).sum().item() / labels.size(0)\n",
        "            acc = torch.eq(labels, preds).sum().item() / labels.size(0)\n",
        "            dev_loss += loss.item()\n",
        "            dev_acc += acc\n",
        "    dev_loss, dev_acc = dev_loss / len(dev_loader), dev_acc / len(dev_loader)\n",
        "\n",
        "    print(f'Epoch {epoch + 1}: train loss: {train_loss:.4f}, train acc: {train_acc:.4f}')\n",
        "    print(f'Epoch {epoch + 1}: dev loss: {dev_loss:.4f}, dev acc: {dev_acc:.4f}')\n",
        "    if dev_acc > best_dev_acc:\n",
        "        best_dev_acc = dev_acc\n",
        "        best_epoch = epoch + 1\n",
        "        torch.save(model, \"LSTM.model.\"+label_to_class+version)\n",
        "        print(f'*** Epoch {epoch + 1}: dev acc higher than best dev acc, model saved!')\n",
        "    print()\n",
        "sec = time.time()-start_time\n",
        "print(f'Training finished! Best epoch is {best_epoch}, best dev acc is {best_dev_acc:.4f}, {sec} seconds used.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_tqNFhDZv7P"
      },
      "source": [
        "# test the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "IK1fchkznxWF"
      },
      "outputs": [],
      "source": [
        "test_data_version = \"A\"\n",
        "BATCH_SIZE = 64\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = nltk.tokenize.TweetTokenizer()\n",
        "\n",
        "def collate_for_test(batch, vocab, device):\n",
        "    texts, labels = zip(*batch)\n",
        "    lengths = [len(text) for text in texts]\n",
        "    word_ids = [[vocab[word] for word in text] for text in texts]\n",
        "    texts = pad_sequence([torch.LongTensor(ids) for ids in word_ids], batch_first=True, padding_value=1)\n",
        "    return texts.to(device), torch.LongTensor(lengths)\n",
        "\n",
        "# init test file\n",
        "test_csv = pd.read_csv('./data/version'+test_data_version+'_test.csv', header=0)\n",
        "\n",
        "# create a new csv df with all the original columns\n",
        "test_csv_new = pd.DataFrame(test_csv, columns=[\"id\",\t\"version\",\t\"batch.tweet\", \"tweet.id\", \"tweet_hashed\", \"hate.speech\", \"offensive.language\"])\n",
        "\n",
        "# preprocess the test data\n",
        "\n",
        "X_test = [tokenizer.tokenize(text.lower()) for text in list(test_csv_new[\"tweet_hashed\"])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "L7RQcZMKJ7gG",
        "outputId": "21e08bf2-e4f6-451b-d7d9-ab758ca18c44"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 53/53 [00:00<00:00, 126.03it/s]\n",
            "100%|██████████| 53/53 [00:00<00:00, 140.73it/s]\n",
            "100%|██████████| 53/53 [00:01<00:00, 48.13it/s]\n",
            "100%|██████████| 53/53 [00:00<00:00, 119.10it/s]\n",
            "100%|██████████| 53/53 [00:00<00:00, 137.36it/s]\n",
            "100%|██████████| 53/53 [00:00<00:00, 155.78it/s]\n",
            "100%|██████████| 53/53 [00:00<00:00, 165.49it/s]\n",
            "100%|██████████| 53/53 [00:00<00:00, 166.30it/s]\n",
            "100%|██████████| 53/53 [00:00<00:00, 163.35it/s]\n",
            "100%|██████████| 53/53 [00:00<00:00, 162.83it/s]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7c4b0a6f-6234-4902-b74c-be2a6571e299\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>version</th>\n",
              "      <th>batch.tweet</th>\n",
              "      <th>tweet.id</th>\n",
              "      <th>tweet_hashed</th>\n",
              "      <th>hate.speech</th>\n",
              "      <th>offensive.language</th>\n",
              "      <th>hate.speech_preds_A</th>\n",
              "      <th>hate.speech_preds_A_scores</th>\n",
              "      <th>hate.speech_preds_B</th>\n",
              "      <th>...</th>\n",
              "      <th>offensive.language_preds_A</th>\n",
              "      <th>offensive.language_preds_A_scores</th>\n",
              "      <th>offensive.language_preds_B</th>\n",
              "      <th>offensive.language_preds_B_scores</th>\n",
              "      <th>offensive.language_preds_C</th>\n",
              "      <th>offensive.language_preds_C_scores</th>\n",
              "      <th>offensive.language_preds_D</th>\n",
              "      <th>offensive.language_preds_D_scores</th>\n",
              "      <th>offensive.language_preds_E</th>\n",
              "      <th>offensive.language_preds_E_scores</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>125</td>\n",
              "      <td>E</td>\n",
              "      <td>R1</td>\n",
              "      <td>1</td>\n",
              "      <td>@###### bro that hoe live</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.062568</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.903320</td>\n",
              "      <td>1</td>\n",
              "      <td>0.844781</td>\n",
              "      <td>1</td>\n",
              "      <td>0.873763</td>\n",
              "      <td>1</td>\n",
              "      <td>0.785041</td>\n",
              "      <td>1</td>\n",
              "      <td>0.873017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>173</td>\n",
              "      <td>E</td>\n",
              "      <td>R1</td>\n",
              "      <td>1</td>\n",
              "      <td>@###### bro that hoe live</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.062568</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.903320</td>\n",
              "      <td>1</td>\n",
              "      <td>0.844781</td>\n",
              "      <td>1</td>\n",
              "      <td>0.873763</td>\n",
              "      <td>1</td>\n",
              "      <td>0.785041</td>\n",
              "      <td>1</td>\n",
              "      <td>0.873017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>219</td>\n",
              "      <td>E</td>\n",
              "      <td>R1</td>\n",
              "      <td>1</td>\n",
              "      <td>@###### bro that hoe live</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.062568</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.903320</td>\n",
              "      <td>1</td>\n",
              "      <td>0.844781</td>\n",
              "      <td>1</td>\n",
              "      <td>0.873763</td>\n",
              "      <td>1</td>\n",
              "      <td>0.785041</td>\n",
              "      <td>1</td>\n",
              "      <td>0.873017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>223</td>\n",
              "      <td>E</td>\n",
              "      <td>R1</td>\n",
              "      <td>1</td>\n",
              "      <td>@###### bro that hoe live</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.062568</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.903320</td>\n",
              "      <td>1</td>\n",
              "      <td>0.844781</td>\n",
              "      <td>1</td>\n",
              "      <td>0.873763</td>\n",
              "      <td>1</td>\n",
              "      <td>0.785041</td>\n",
              "      <td>1</td>\n",
              "      <td>0.873017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>228</td>\n",
              "      <td>E</td>\n",
              "      <td>R1</td>\n",
              "      <td>1</td>\n",
              "      <td>@###### bro that hoe live</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.062568</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.903320</td>\n",
              "      <td>1</td>\n",
              "      <td>0.844781</td>\n",
              "      <td>1</td>\n",
              "      <td>0.873763</td>\n",
              "      <td>1</td>\n",
              "      <td>0.785041</td>\n",
              "      <td>1</td>\n",
              "      <td>0.873017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3330</th>\n",
              "      <td>996</td>\n",
              "      <td>E</td>\n",
              "      <td>R49</td>\n",
              "      <td>2999</td>\n",
              "      <td>RT @###### My favorite episode of Friends is t...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.255284</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.216544</td>\n",
              "      <td>0</td>\n",
              "      <td>0.307929</td>\n",
              "      <td>1</td>\n",
              "      <td>0.506910</td>\n",
              "      <td>1</td>\n",
              "      <td>0.766770</td>\n",
              "      <td>1</td>\n",
              "      <td>0.983291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3331</th>\n",
              "      <td>1073</td>\n",
              "      <td>E</td>\n",
              "      <td>R49</td>\n",
              "      <td>2999</td>\n",
              "      <td>RT @###### My favorite episode of Friends is t...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.255284</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.216544</td>\n",
              "      <td>0</td>\n",
              "      <td>0.307929</td>\n",
              "      <td>1</td>\n",
              "      <td>0.506910</td>\n",
              "      <td>1</td>\n",
              "      <td>0.766770</td>\n",
              "      <td>1</td>\n",
              "      <td>0.983291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3332</th>\n",
              "      <td>1472</td>\n",
              "      <td>E</td>\n",
              "      <td>R49</td>\n",
              "      <td>2999</td>\n",
              "      <td>RT @###### My favorite episode of Friends is t...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.255284</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.216544</td>\n",
              "      <td>0</td>\n",
              "      <td>0.307929</td>\n",
              "      <td>1</td>\n",
              "      <td>0.506910</td>\n",
              "      <td>1</td>\n",
              "      <td>0.766770</td>\n",
              "      <td>1</td>\n",
              "      <td>0.983291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3333</th>\n",
              "      <td>1481</td>\n",
              "      <td>E</td>\n",
              "      <td>R49</td>\n",
              "      <td>2999</td>\n",
              "      <td>RT @###### My favorite episode of Friends is t...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.255284</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.216544</td>\n",
              "      <td>0</td>\n",
              "      <td>0.307929</td>\n",
              "      <td>1</td>\n",
              "      <td>0.506910</td>\n",
              "      <td>1</td>\n",
              "      <td>0.766770</td>\n",
              "      <td>1</td>\n",
              "      <td>0.983291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3334</th>\n",
              "      <td>1482</td>\n",
              "      <td>E</td>\n",
              "      <td>R49</td>\n",
              "      <td>2999</td>\n",
              "      <td>RT @###### My favorite episode of Friends is t...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.255284</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.216544</td>\n",
              "      <td>0</td>\n",
              "      <td>0.307929</td>\n",
              "      <td>1</td>\n",
              "      <td>0.506910</td>\n",
              "      <td>1</td>\n",
              "      <td>0.766770</td>\n",
              "      <td>1</td>\n",
              "      <td>0.983291</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3335 rows × 27 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c4b0a6f-6234-4902-b74c-be2a6571e299')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7c4b0a6f-6234-4902-b74c-be2a6571e299 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7c4b0a6f-6234-4902-b74c-be2a6571e299');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        id version batch.tweet  tweet.id  \\\n",
              "0      125       E          R1         1   \n",
              "1      173       E          R1         1   \n",
              "2      219       E          R1         1   \n",
              "3      223       E          R1         1   \n",
              "4      228       E          R1         1   \n",
              "...    ...     ...         ...       ...   \n",
              "3330   996       E         R49      2999   \n",
              "3331  1073       E         R49      2999   \n",
              "3332  1472       E         R49      2999   \n",
              "3333  1481       E         R49      2999   \n",
              "3334  1482       E         R49      2999   \n",
              "\n",
              "                                           tweet_hashed  hate.speech  \\\n",
              "0                             @###### bro that hoe live          1.0   \n",
              "1                             @###### bro that hoe live          0.0   \n",
              "2                             @###### bro that hoe live          0.0   \n",
              "3                             @###### bro that hoe live          0.0   \n",
              "4                             @###### bro that hoe live          0.0   \n",
              "...                                                 ...          ...   \n",
              "3330  RT @###### My favorite episode of Friends is t...          0.0   \n",
              "3331  RT @###### My favorite episode of Friends is t...          0.0   \n",
              "3332  RT @###### My favorite episode of Friends is t...          0.0   \n",
              "3333  RT @###### My favorite episode of Friends is t...          0.0   \n",
              "3334  RT @###### My favorite episode of Friends is t...          0.0   \n",
              "\n",
              "      offensive.language  hate.speech_preds_A  hate.speech_preds_A_scores  \\\n",
              "0                      0                    0                    0.062568   \n",
              "1                      1                    0                    0.062568   \n",
              "2                      1                    0                    0.062568   \n",
              "3                      1                    0                    0.062568   \n",
              "4                      1                    0                    0.062568   \n",
              "...                  ...                  ...                         ...   \n",
              "3330                   1                    0                    0.255284   \n",
              "3331                   0                    0                    0.255284   \n",
              "3332                   0                    0                    0.255284   \n",
              "3333                   0                    0                    0.255284   \n",
              "3334                   0                    0                    0.255284   \n",
              "\n",
              "      hate.speech_preds_B  ...  offensive.language_preds_A  \\\n",
              "0                       0  ...                           1   \n",
              "1                       0  ...                           1   \n",
              "2                       0  ...                           1   \n",
              "3                       0  ...                           1   \n",
              "4                       0  ...                           1   \n",
              "...                   ...  ...                         ...   \n",
              "3330                    1  ...                           0   \n",
              "3331                    1  ...                           0   \n",
              "3332                    1  ...                           0   \n",
              "3333                    1  ...                           0   \n",
              "3334                    1  ...                           0   \n",
              "\n",
              "      offensive.language_preds_A_scores  offensive.language_preds_B  \\\n",
              "0                              0.903320                           1   \n",
              "1                              0.903320                           1   \n",
              "2                              0.903320                           1   \n",
              "3                              0.903320                           1   \n",
              "4                              0.903320                           1   \n",
              "...                                 ...                         ...   \n",
              "3330                           0.216544                           0   \n",
              "3331                           0.216544                           0   \n",
              "3332                           0.216544                           0   \n",
              "3333                           0.216544                           0   \n",
              "3334                           0.216544                           0   \n",
              "\n",
              "      offensive.language_preds_B_scores  offensive.language_preds_C  \\\n",
              "0                              0.844781                           1   \n",
              "1                              0.844781                           1   \n",
              "2                              0.844781                           1   \n",
              "3                              0.844781                           1   \n",
              "4                              0.844781                           1   \n",
              "...                                 ...                         ...   \n",
              "3330                           0.307929                           1   \n",
              "3331                           0.307929                           1   \n",
              "3332                           0.307929                           1   \n",
              "3333                           0.307929                           1   \n",
              "3334                           0.307929                           1   \n",
              "\n",
              "      offensive.language_preds_C_scores  offensive.language_preds_D  \\\n",
              "0                              0.873763                           1   \n",
              "1                              0.873763                           1   \n",
              "2                              0.873763                           1   \n",
              "3                              0.873763                           1   \n",
              "4                              0.873763                           1   \n",
              "...                                 ...                         ...   \n",
              "3330                           0.506910                           1   \n",
              "3331                           0.506910                           1   \n",
              "3332                           0.506910                           1   \n",
              "3333                           0.506910                           1   \n",
              "3334                           0.506910                           1   \n",
              "\n",
              "      offensive.language_preds_D_scores  offensive.language_preds_E  \\\n",
              "0                              0.785041                           1   \n",
              "1                              0.785041                           1   \n",
              "2                              0.785041                           1   \n",
              "3                              0.785041                           1   \n",
              "4                              0.785041                           1   \n",
              "...                                 ...                         ...   \n",
              "3330                           0.766770                           1   \n",
              "3331                           0.766770                           1   \n",
              "3332                           0.766770                           1   \n",
              "3333                           0.766770                           1   \n",
              "3334                           0.766770                           1   \n",
              "\n",
              "      offensive.language_preds_E_scores  \n",
              "0                              0.873017  \n",
              "1                              0.873017  \n",
              "2                              0.873017  \n",
              "3                              0.873017  \n",
              "4                              0.873017  \n",
              "...                                 ...  \n",
              "3330                           0.983291  \n",
              "3331                           0.983291  \n",
              "3332                           0.983291  \n",
              "3333                           0.983291  \n",
              "3334                           0.983291  \n",
              "\n",
              "[3335 rows x 27 columns]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# choose trained model version to test\n",
        "\n",
        "for label_to_test in [\"hate.speech\", \"offensive.language\"]:\n",
        "  for version_to_test in [\"A\",\"B\",\"C\",\"D\",\"E\"]:\n",
        "\n",
        "    vocab_test = torch.load(\"LSTM.vocab.\"+label_to_test+version_to_test, map_location=DEVICE)\n",
        "    model_test = torch.load(\"LSTM.model.\"+label_to_test+version_to_test, map_location=DEVICE)\n",
        "    \n",
        "    y_test = list(test_csv_new[label_to_test])\n",
        "    test_data = list(zip(X_test, y_test))\n",
        "\n",
        "    test_loader = DataLoader(dataset=test_data,\n",
        "                            batch_size=BATCH_SIZE,\n",
        "                            collate_fn=lambda batch: collate_for_test(batch, vocab_test, DEVICE))\n",
        "\n",
        "    model_test.eval()\n",
        "    preds_list = []\n",
        "    preds_scores = []\n",
        "    with torch.no_grad():\n",
        "        for texts, lengths in tqdm(test_loader):\n",
        "            output = model_test(texts, lengths)\n",
        "            preds = torch.round(output)\n",
        "            preds_list.extend(preds.tolist())\n",
        "            preds_scores.extend(output.tolist())\n",
        "\n",
        "    preds_list = [int(i) for i in preds_list]\n",
        "\n",
        "    if label_to_test == \"hate.speech\":\n",
        "      if version_to_test == \"A\":\n",
        "        column = 7\n",
        "      elif version_to_test == \"B\":\n",
        "        column = 9\n",
        "      elif version_to_test == \"C\":\n",
        "        column = 11\n",
        "      elif version_to_test == \"D\":\n",
        "        column = 13\n",
        "      elif version_to_test == \"E\":\n",
        "        column = 15\n",
        "      else:\n",
        "        raise KeyError\n",
        "    elif label_to_test == \"offensive.language\":\n",
        "      if version_to_test == \"A\":\n",
        "        column = 17\n",
        "      elif version_to_test == \"B\":\n",
        "        column = 19\n",
        "      elif version_to_test == \"C\":\n",
        "        column = 21\n",
        "      elif version_to_test == \"D\":\n",
        "        column = 23\n",
        "      elif version_to_test == \"E\":\n",
        "        column = 25\n",
        "      else:\n",
        "        raise KeyError\n",
        "    else:\n",
        "      raise KeyError\n",
        "\n",
        "    test_csv_new.insert(column,label_to_test+\"_preds_\"+version_to_test,preds_list)\n",
        "    test_csv_new.insert(column+1,label_to_test+\"_preds_\"+version_to_test+\"_scores\",preds_scores)\n",
        "\n",
        "test_csv_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "K8UpyrfwqdFG"
      },
      "outputs": [],
      "source": [
        "test_csv_new.to_csv(\"./preds/lstm_test\"+test_data_version+\".csv\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
