{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9BU18b13VYW",
        "outputId": "3c0d3424-df92-49ca-ef9c-5d32fcdbe027"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDzG0yQ23VYa",
        "outputId": "9df7d1d9-3d81-4d30-ed7c-b9d860f18ddf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/hate_speech/models\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/hate_speech/models"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LSTM for \"offensive.language\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "label_to_class = \"offensive.language\" # enter the label to be classified"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wiId22Up3VYb"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import numpy as np\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_JA4Z0J3VYb"
      },
      "outputs": [],
      "source": [
        "# build the model\n",
        "class LSTM(nn.Module):\n",
        "  def __init__(self,vocab_size, emb_size, lstm_size, hidden_size, dropout):\n",
        "    super().__init__()\n",
        "    self.emb = nn.Embedding(vocab_size, emb_size)\n",
        "    self.lstm = nn.LSTM(emb_size, lstm_size, bidirectional=True, batch_first=True)\n",
        "    self.hidden = nn.Linear(lstm_size*2, hidden_size)\n",
        "    self.linear = nn.Linear(hidden_size, 1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, input, lengths): # input.shape: (batch_size, texts_length)\n",
        "    emb = self.emb(input) # (batch_size, texts_length, emb_size)\n",
        "    emb = self.dropout(emb)\n",
        "    packed = pack_padded_sequence(emb, lengths, batch_first=True, enforce_sorted=False)  #PackedSequence: data (packed length, lstm_size*2)\n",
        "    lstm, _ = self.lstm(packed.float())  # (batch_size, texts_length, lstm_size*2)\n",
        "    padded, _ = pad_packed_sequence(lstm, batch_first=True)\n",
        "    output = torch.max(padded, dim=1).values # max pooling, (batch_size, lstm_size*2)\n",
        "    output = self.hidden(self.dropout(output)) # (batch_size, hidden_size)\n",
        "    output = self.linear(self.dropout(output)) # (batch_size, 1)\n",
        "    output = self.sigmoid(output)\n",
        "    return output.squeeze() # (batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4Io0UcH3VYe"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 15\n",
        "BATCH_SIZE = 64\n",
        "EMB_SIZE = 256\n",
        "LSTM_SIZE = 256\n",
        "HIDDEN_SIZE = 128\n",
        "DROPOUT = 0.3\n",
        "VOCAB_SIZE=5000\n",
        "LEARNING_RATE = 0.00001\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NHYbCdiV5Rf"
      },
      "outputs": [],
      "source": [
        "csv = pd.read_csv('../data/ourdata/full_train.csv', names=[label_to_class,'tweet_hashed'],header=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YydMznHk9_5_"
      },
      "outputs": [],
      "source": [
        "# create a new csv df\n",
        "csv_new = pd.DataFrame(csv, columns=[label_to_class, \"tweet_hashed\"])\n",
        "# drop all rows that have any NaN values\n",
        "csv_new_clean = csv_new.dropna(axis=0,how=\"any\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLD_0oAU9_6B"
      },
      "outputs": [],
      "source": [
        "train_csv, dev_csv = train_test_split(csv_new_clean, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMb3fzud6k4G"
      },
      "outputs": [],
      "source": [
        "X_train = [nltk.word_tokenize(text) for text in list(train_csv[\"tweet_hashed\"])]\n",
        "X_dev = [nltk.word_tokenize(text) for text in list(dev_csv[\"tweet_hashed\"])]\n",
        "\n",
        "y_train = list(train_csv[label_to_class])\n",
        "y_dev = list(dev_csv[label_to_class])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQ2iOqJZ6k4H"
      },
      "outputs": [],
      "source": [
        "train_data = list(zip(X_train, y_train))\n",
        "dev_data = list(zip(X_dev, y_dev))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hchtnPii6k4H"
      },
      "outputs": [],
      "source": [
        "vocab = build_vocab_from_iterator(X_train, max_tokens=VOCAB_SIZE, specials=[\"<unk>\", \"<pad>\"])\n",
        "vocab.set_default_index(vocab[\"<unk>\"])  # index 0 reserved for '<unk>' as default, 1 reserved for '<pad>'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htdTscnU6k4H"
      },
      "outputs": [],
      "source": [
        "def collate(batch, vocab, device):\n",
        "    lengths = []\n",
        "    word_ids = []\n",
        "    labels = []\n",
        "    for b in batch:\n",
        "        text = b[0]\n",
        "        label = b[1]\n",
        "        ids = []\n",
        "        lengths.append(len(text))\n",
        "        labels.append(label)\n",
        "        for word in text:\n",
        "            ids.append(vocab[word])\n",
        "        word_ids.append(ids)\n",
        "    texts = pad_sequence([torch.LongTensor(ids) for ids in word_ids], batch_first=True, padding_value=1)\n",
        "    return texts.to(device), torch.tensor(labels).to(device), torch.LongTensor(lengths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RW_F8wlH9afa"
      },
      "outputs": [],
      "source": [
        "def collate(batch, vocab, device):\n",
        "    texts, labels = zip(*batch)\n",
        "    lengths = [len(text) for text in texts]\n",
        "    word_ids = [[vocab[word] for word in text] for text in texts]\n",
        "    texts = pad_sequence([torch.LongTensor(ids) for ids in word_ids], batch_first=True, padding_value=1)\n",
        "    return texts.to(device), torch.tensor(labels).to(device), torch.LongTensor(lengths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCbeba2FV5Rh"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(dataset=train_data,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          shuffle=True,\n",
        "                          collate_fn=lambda batch: collate(batch, vocab, DEVICE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iNVb2dSV5Ri"
      },
      "outputs": [],
      "source": [
        "dev_loader = DataLoader(dataset=dev_data,\n",
        "                        batch_size=BATCH_SIZE,\n",
        "                        collate_fn=lambda batch: collate(batch, vocab, DEVICE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EKPiWpZ3VYf"
      },
      "outputs": [],
      "source": [
        "model = LSTM(VOCAB_SIZE, EMB_SIZE, LSTM_SIZE, HIDDEN_SIZE, DROPOUT).to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "criterion = nn.BCELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-g2v8Gc3VYf",
        "outputId": "7d2f98f9-acb6-4d5c-a98d-a0718915ef75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start training...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 832/832 [00:13<00:00, 59.65it/s]\n",
            "100%|██████████| 208/208 [00:01<00:00, 187.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: train loss: 0.6391, train acc: 0.6565\n",
            "Epoch 1: dev loss: 0.6009, dev acc: 0.7039\n",
            "*** Epoch 1: dev acc higher than best dev acc, model saved!\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 832/832 [00:13<00:00, 62.59it/s]\n",
            "100%|██████████| 208/208 [00:01<00:00, 185.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2: train loss: 0.5915, train acc: 0.6991\n",
            "Epoch 2: dev loss: 0.5533, dev acc: 0.7288\n",
            "*** Epoch 2: dev acc higher than best dev acc, model saved!\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 832/832 [00:13<00:00, 62.54it/s]\n",
            "100%|██████████| 208/208 [00:01<00:00, 186.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3: train loss: 0.5576, train acc: 0.7199\n",
            "Epoch 3: dev loss: 0.5242, dev acc: 0.7458\n",
            "*** Epoch 3: dev acc higher than best dev acc, model saved!\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 832/832 [00:15<00:00, 54.21it/s]\n",
            "100%|██████████| 208/208 [00:01<00:00, 189.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4: train loss: 0.5338, train acc: 0.7406\n",
            "Epoch 4: dev loss: 0.5027, dev acc: 0.7692\n",
            "*** Epoch 4: dev acc higher than best dev acc, model saved!\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 832/832 [00:13<00:00, 63.26it/s]\n",
            "100%|██████████| 208/208 [00:01<00:00, 186.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: train loss: 0.5152, train acc: 0.7560\n",
            "Epoch 5: dev loss: 0.4844, dev acc: 0.7827\n",
            "*** Epoch 5: dev acc higher than best dev acc, model saved!\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 832/832 [00:13<00:00, 62.71it/s]\n",
            "100%|██████████| 208/208 [00:01<00:00, 182.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6: train loss: 0.5015, train acc: 0.7692\n",
            "Epoch 6: dev loss: 0.4699, dev acc: 0.7932\n",
            "*** Epoch 6: dev acc higher than best dev acc, model saved!\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 832/832 [00:13<00:00, 62.89it/s]\n",
            "100%|██████████| 208/208 [00:01<00:00, 190.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7: train loss: 0.4876, train acc: 0.7797\n",
            "Epoch 7: dev loss: 0.4554, dev acc: 0.8021\n",
            "*** Epoch 7: dev acc higher than best dev acc, model saved!\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 832/832 [00:13<00:00, 62.71it/s]\n",
            "100%|██████████| 208/208 [00:01<00:00, 184.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8: train loss: 0.4774, train acc: 0.7862\n",
            "Epoch 8: dev loss: 0.4432, dev acc: 0.8111\n",
            "*** Epoch 8: dev acc higher than best dev acc, model saved!\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 832/832 [00:13<00:00, 62.86it/s]\n",
            "100%|██████████| 208/208 [00:01<00:00, 190.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9: train loss: 0.4666, train acc: 0.7952\n",
            "Epoch 9: dev loss: 0.4342, dev acc: 0.8149\n",
            "*** Epoch 9: dev acc higher than best dev acc, model saved!\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 832/832 [00:13<00:00, 63.19it/s]\n",
            "100%|██████████| 208/208 [00:01<00:00, 187.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10: train loss: 0.4600, train acc: 0.8006\n",
            "Epoch 10: dev loss: 0.4268, dev acc: 0.8200\n",
            "*** Epoch 10: dev acc higher than best dev acc, model saved!\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 832/832 [00:13<00:00, 62.56it/s]\n",
            "100%|██████████| 208/208 [00:01<00:00, 185.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11: train loss: 0.4510, train acc: 0.8068\n",
            "Epoch 11: dev loss: 0.4219, dev acc: 0.8229\n",
            "*** Epoch 11: dev acc higher than best dev acc, model saved!\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 832/832 [00:13<00:00, 62.85it/s]\n",
            "100%|██████████| 208/208 [00:01<00:00, 183.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12: train loss: 0.4458, train acc: 0.8101\n",
            "Epoch 12: dev loss: 0.4165, dev acc: 0.8273\n",
            "*** Epoch 12: dev acc higher than best dev acc, model saved!\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 832/832 [00:13<00:00, 61.49it/s]\n",
            "100%|██████████| 208/208 [00:01<00:00, 185.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13: train loss: 0.4387, train acc: 0.8115\n",
            "Epoch 13: dev loss: 0.4136, dev acc: 0.8299\n",
            "*** Epoch 13: dev acc higher than best dev acc, model saved!\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 832/832 [00:13<00:00, 62.27it/s]\n",
            "100%|██████████| 208/208 [00:01<00:00, 189.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14: train loss: 0.4347, train acc: 0.8156\n",
            "Epoch 14: dev loss: 0.4111, dev acc: 0.8313\n",
            "*** Epoch 14: dev acc higher than best dev acc, model saved!\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 832/832 [00:13<00:00, 62.29it/s]\n",
            "100%|██████████| 208/208 [00:01<00:00, 186.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15: train loss: 0.4302, train acc: 0.8189\n",
            "Epoch 15: dev loss: 0.4085, dev acc: 0.8338\n",
            "*** Epoch 15: dev acc higher than best dev acc, model saved!\n",
            "\n",
            "Training finished! Best epoch is 15, best dev acc is 0.8338, 14.539275646209717 seconds used.\n"
          ]
        }
      ],
      "source": [
        "best_dev_acc = 0\n",
        "best_epoch = 0\n",
        "print(f'Start training...')\n",
        "for epoch in range(EPOCHS):\n",
        "    start_time = time.time()\n",
        "    # train\n",
        "    train_loss = 0\n",
        "    train_acc = 0\n",
        "    model.train()\n",
        "    for texts, labels, lengths in tqdm(train_loader):\n",
        "        output = model(texts, lengths)\n",
        "        preds = torch.round(output)\n",
        "        #acc = (output.ge(0.5) == labels).sum().item() / labels.size(0)\n",
        "        acc = torch.eq(labels, preds).sum().item() / labels.size(0)\n",
        "        model.zero_grad()\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "        train_acc += acc\n",
        "    train_loss, train_acc = train_loss / len(train_loader), train_acc / len(train_loader)\n",
        "    \n",
        "    # dev\n",
        "    dev_loss = 0\n",
        "    dev_acc = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for texts, labels, lengths in tqdm(dev_loader):\n",
        "            output = model(texts, lengths)\n",
        "            loss = criterion(output, labels)\n",
        "            preds = torch.round(output)\n",
        "            #acc = (output.ge(0.5) == labels).sum().item() / labels.size(0)\n",
        "            acc = torch.eq(labels, preds).sum().item() / labels.size(0)\n",
        "            dev_loss += loss.item()\n",
        "            dev_acc += acc\n",
        "    dev_loss, dev_acc = dev_loss / len(dev_loader), dev_acc / len(dev_loader)\n",
        "\n",
        "    print(f'Epoch {epoch + 1}: train loss: {train_loss:.4f}, train acc: {train_acc:.4f}')\n",
        "    print(f'Epoch {epoch + 1}: dev loss: {dev_loss:.4f}, dev acc: {dev_acc:.4f}')\n",
        "    if dev_acc > best_dev_acc:\n",
        "        best_dev_acc = dev_acc\n",
        "        best_epoch = epoch + 1\n",
        "        torch.save(model, \"LSTM.\"+label_to_class)\n",
        "        print(f'*** Epoch {epoch + 1}: dev acc higher than best dev acc, model saved!')\n",
        "    print()\n",
        "sec = time.time()-start_time\n",
        "print(f'Training finished! Best epoch is {best_epoch}, best dev acc is {best_dev_acc:.4f}, {sec} seconds used.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_tqNFhDZv7P"
      },
      "source": [
        "# test the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nja9i0Oq3VYg"
      },
      "outputs": [],
      "source": [
        "# test the final model with test file\n",
        "test_csv = pd.read_csv('../data/ourdata/full_test.csv', header=0)\n",
        "\n",
        "# create a new csv df\n",
        "test_csv_new = pd.DataFrame(test_csv, columns=[\"id\",\t\"version\",\t\"batch.tweet\", label_to_class, \"tweet.id\", \"tweet_hashed\"])\n",
        "# drop all rows that have any NaN values\n",
        "test_csv_new_clean = test_csv_new.dropna(axis=0,how=\"any\")\n",
        "\n",
        "X_test = [nltk.word_tokenize(text) for text in list(test_csv_new_clean[\"tweet_hashed\"])]\n",
        "y_test = list(test_csv_new_clean[label_to_class])\n",
        "\n",
        "test_data = list(zip(X_test, y_test))\n",
        "\n",
        "test_loader = DataLoader(dataset=test_data,\n",
        "                        batch_size=BATCH_SIZE,\n",
        "                        collate_fn=lambda batch: collate(batch, vocab, DEVICE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPiiWYTtP8aZ",
        "outputId": "62a81841-51cb-4d6e-c4b4-be67b5f82d4a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 349/349 [00:01<00:00, 224.68it/s]\n"
          ]
        }
      ],
      "source": [
        "best_model = torch.load(\"LSTM.\"+label_to_class, map_location=DEVICE)\n",
        "best_model.eval()\n",
        "preds_list = []\n",
        "labels_list = []\n",
        "with torch.no_grad():\n",
        "    for texts, labels, lengths in tqdm(test_loader):\n",
        "        output = best_model(texts, lengths)\n",
        "        preds = torch.round(output)\n",
        "        labels_list.extend(labels.tolist())\n",
        "        preds_list.extend(preds.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyS0zqIeS-5S",
        "outputId": "713d9b69-1768-49ec-8b2d-2003155905a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        precision    recall  f1-score   support\n",
            "\n",
            "non-offensive.language       0.75      0.75      0.75      9832\n",
            "    offensive.language       0.80      0.80      0.80     12450\n",
            "\n",
            "              accuracy                           0.78     22282\n",
            "             macro avg       0.78      0.78      0.78     22282\n",
            "          weighted avg       0.78      0.78      0.78     22282\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(labels_list, preds_list, target_names=[\"non-\"+label_to_class,label_to_class]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6s-_0n2DClJ",
        "outputId": "258d32a1-625b-4e93-cc6e-e2209f4dd60a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([0.74885752, 0.80233213]),\n",
              " array([0.75      , 0.80136546]),\n",
              " array([0.74942832, 0.8018485 ]),\n",
              " array([ 9832, 12450]))"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "precision_recall_fscore_support(labels_list, preds_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKQZiBXeDK3g"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSpVxSRgmT6G"
      },
      "outputs": [],
      "source": [
        "test_csv_new_clean.insert(6,label_to_class+\"_preds_lstm_full\",preds_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Hh9ofvhNpTrY",
        "outputId": "dca81ce9-20e2-4b99-b851-b367205532ec"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ba5286e0-36b9-4d41-918d-c99c4a77b318\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>version</th>\n",
              "      <th>batch.tweet</th>\n",
              "      <th>offensive.language</th>\n",
              "      <th>tweet.id</th>\n",
              "      <th>tweet_hashed</th>\n",
              "      <th>offensive.language_preds_lstm_full</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>125</td>\n",
              "      <td>E</td>\n",
              "      <td>R1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>@###### bro that hoe live</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>173</td>\n",
              "      <td>E</td>\n",
              "      <td>R1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>@###### bro that hoe live</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>219</td>\n",
              "      <td>E</td>\n",
              "      <td>R1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>@###### bro that hoe live</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>223</td>\n",
              "      <td>E</td>\n",
              "      <td>R1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>@###### bro that hoe live</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>228</td>\n",
              "      <td>E</td>\n",
              "      <td>R1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>@###### bro that hoe live</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22297</th>\n",
              "      <td>1315</td>\n",
              "      <td>A</td>\n",
              "      <td>R43</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2993</td>\n",
              "      <td>Lol that's some hoe shit</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22298</th>\n",
              "      <td>1324</td>\n",
              "      <td>A</td>\n",
              "      <td>R43</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2993</td>\n",
              "      <td>Lol that's some hoe shit</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22299</th>\n",
              "      <td>1312</td>\n",
              "      <td>A</td>\n",
              "      <td>R49</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2999</td>\n",
              "      <td>RT @###### My favorite episode of Friends is t...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22300</th>\n",
              "      <td>1315</td>\n",
              "      <td>A</td>\n",
              "      <td>R49</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2999</td>\n",
              "      <td>RT @###### My favorite episode of Friends is t...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22301</th>\n",
              "      <td>1324</td>\n",
              "      <td>A</td>\n",
              "      <td>R49</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2999</td>\n",
              "      <td>RT @###### My favorite episode of Friends is t...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>22282 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ba5286e0-36b9-4d41-918d-c99c4a77b318')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ba5286e0-36b9-4d41-918d-c99c4a77b318 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ba5286e0-36b9-4d41-918d-c99c4a77b318');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         id version batch.tweet  offensive.language  tweet.id  \\\n",
              "0       125       E          R1                 0.0         1   \n",
              "1       173       E          R1                 1.0         1   \n",
              "2       219       E          R1                 1.0         1   \n",
              "3       223       E          R1                 1.0         1   \n",
              "4       228       E          R1                 1.0         1   \n",
              "...     ...     ...         ...                 ...       ...   \n",
              "22297  1315       A         R43                 1.0      2993   \n",
              "22298  1324       A         R43                 1.0      2993   \n",
              "22299  1312       A         R49                 1.0      2999   \n",
              "22300  1315       A         R49                 0.0      2999   \n",
              "22301  1324       A         R49                 1.0      2999   \n",
              "\n",
              "                                            tweet_hashed  \\\n",
              "0                              @###### bro that hoe live   \n",
              "1                              @###### bro that hoe live   \n",
              "2                              @###### bro that hoe live   \n",
              "3                              @###### bro that hoe live   \n",
              "4                              @###### bro that hoe live   \n",
              "...                                                  ...   \n",
              "22297                           Lol that's some hoe shit   \n",
              "22298                           Lol that's some hoe shit   \n",
              "22299  RT @###### My favorite episode of Friends is t...   \n",
              "22300  RT @###### My favorite episode of Friends is t...   \n",
              "22301  RT @###### My favorite episode of Friends is t...   \n",
              "\n",
              "       offensive.language_preds_lstm_full  \n",
              "0                                     1.0  \n",
              "1                                     1.0  \n",
              "2                                     1.0  \n",
              "3                                     1.0  \n",
              "4                                     1.0  \n",
              "...                                   ...  \n",
              "22297                                 1.0  \n",
              "22298                                 1.0  \n",
              "22299                                 0.0  \n",
              "22300                                 0.0  \n",
              "22301                                 0.0  \n",
              "\n",
              "[22282 rows x 7 columns]"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_csv_new_clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8UpyrfwqdFG"
      },
      "outputs": [],
      "source": [
        "test_csv_new_clean.to_csv(\"../data/preds/\" + label_to_class+ \"_preds_lstm_full.csv\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12 (default, Oct 12 2021, 06:23:56) \n[Clang 10.0.0 ]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
